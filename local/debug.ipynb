{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import (\n",
    "    datetime, \n",
    "    timedelta,\n",
    "    timezone\n",
    ")\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_weekend():\n",
    "    today = datetime.now()\n",
    "    # Calculate days until next Saturday (5) and Sunday (6) respectively\n",
    "    days_until_friday = (4 - today.weekday()) % 7\n",
    "    days_until_saturday = (5 - today.weekday()) % 7\n",
    "    days_until_sunday = (6 - today.weekday()) % 7\n",
    "    # Calculate and format the dates\n",
    "    next_friday = (today + timedelta(days=days_until_friday)).strftime(\"%Y-%m-%d\")\n",
    "    next_saturday = (today + timedelta(days=days_until_saturday)).strftime(\"%Y-%m-%d\")\n",
    "    next_sunday = (today + timedelta(days=days_until_sunday)).strftime(\"%Y-%m-%d\")\n",
    "    # Return as a list\n",
    "    return [next_friday, next_saturday, next_sunday]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_closeness_to_var(df, column_name, variable_to_compare):\n",
    "    # Compute closeness rank\n",
    "    df[f'closeness_rank'] = abs(df[column_name] - variable_to_compare)\n",
    "    \n",
    "    # Find the maximum closeness rank\n",
    "    max_value = df[column_name].max()\n",
    "    \n",
    "    # Handle the case where max_value is zero (all values are equal to variable_to_compare)\n",
    "    if max_value == 0:\n",
    "        df[f'normalized_closeness_{column_name}'] = 1  # All values get the max score\n",
    "    else:\n",
    "        # Normalize closeness\n",
    "        df[f'normalized_closeness_{column_name}'] = 1 - (df[f'closeness_rank'] / max_value)\n",
    "    \n",
    "    # Drop the temporary column\n",
    "    df = df.drop('closeness_rank', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_path():\n",
    "    current_folder = os.path.dirname(\".\")\n",
    "    return os.path.join(current_folder, \"./data\")\n",
    "\n",
    "def get_distances_path():\n",
    "    return os.path.join(get_data_path(), \"dist.csv\")\n",
    "\n",
    "get_data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def surf_the_web(id, param_type):\n",
    "#     if param_type == \"wave\":\n",
    "#         url = f\"https://services.surfline.com/kbyg/spots/forecasts/wave?spotId={id}&days=5&intervalHours=1&cacheEnabled=true&units%5BswellHeight%5D=FT&units%5BwaveHeight%5D=FT\"\n",
    "#     elif param_type == \"wind\":\n",
    "#         url = f\"https://services.surfline.com/kbyg/spots/forecasts/wind?spotId={id}&days=5&intervalHours=1&corrected=false&cacheEnabled=true&units%5BwindSpeed%5D=MPH\"\n",
    "#     elif param_type == \"sunlight\":\n",
    "#         url = f\"https://services.surfline.com/kbyg/spots/forecasts/sunlight?spotId={id}&days=16&intervalHours=1\"\n",
    "#     elif param_type == \"rating\":\n",
    "#         url = f\"https://services.surfline.com/kbyg/spots/forecasts/rating?spotId={id}&days=5&intervalHours=1&cacheEnabled=true\"\n",
    "    \n",
    "#     current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "#     file_name = os.path.join(get_data_path(), \"cache\", f\"{id}_{param_type}_{current_date}.json\")\n",
    "\n",
    "#     if os.path.exists(file_name):\n",
    "#         with open(file_name, 'r') as file:\n",
    "#             return json.loads(file.read())\n",
    "#     else:\n",
    "#         response = requests.get(url)\n",
    "\n",
    "#         # Check if the request was successful (status code 200)\n",
    "#         if response.status_code == 200:\n",
    "#             # Parse the JSON content\n",
    "#             json_object = response.json()\n",
    "        \n",
    "#             json_string = json.dumps(json_object)\n",
    "\n",
    "#             with open(file_name, 'w') as file:\n",
    "#                 file.write(json_string)\n",
    "\n",
    "#             return json_object\n",
    "#         else:\n",
    "#             raise Exception(response)\n",
    "        \n",
    "def surf_the_web(id, param_type):\n",
    "    if param_type == \"wave\":\n",
    "        url = f\"https://services.surfline.com/kbyg/spots/forecasts/wave?spotId={id}&days=5&intervalHours=1&cacheEnabled=true&units%5BswellHeight%5D=FT&units%5BwaveHeight%5D=FT\"\n",
    "    elif param_type == \"wind\":\n",
    "        url = f\"https://services.surfline.com/kbyg/spots/forecasts/wind?spotId={id}&days=5&intervalHours=1&corrected=false&cacheEnabled=true&units%5BwindSpeed%5D=MPH\"\n",
    "    elif param_type == \"sunlight\":\n",
    "        url = f\"https://services.surfline.com/kbyg/spots/forecasts/sunlight?spotId={id}&days=16&intervalHours=1\"\n",
    "    elif param_type == \"rating\":\n",
    "        url = f\"https://services.surfline.com/kbyg/spots/forecasts/rating?spotId={id}&days=5&intervalHours=1&cacheEnabled=true\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        json_object = response.json()\n",
    "        return json_object\n",
    "    else:\n",
    "        raise Exception(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unix_time_convert(unix):\n",
    "    return datetime.fromtimestamp(unix, tz=timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(id):\n",
    "    wave_response = surf_the_web(id, 'wave')\n",
    "\n",
    "    wave_info = []  # Assuming this is defined somewhere above your code\n",
    "\n",
    "    for wave in wave_response[\"data\"][\"wave\"]: \n",
    "        spot_id = id\n",
    "        surf = wave[\"surf\"]\n",
    "        swells = wave[\"swells\"]\n",
    "        swell_period = -1\n",
    "\n",
    "        # Find the swell with the maximum impact if swells exist\n",
    "        if swells:\n",
    "            max_impact_swell = max(swells, key=lambda swell: swell[\"impact\"])\n",
    "            swell_period = max_impact_swell[\"period\"]\n",
    "\n",
    "        timestamp = unix_time_convert(wave[\"timestamp\"])\n",
    "        min_wave_size = surf[\"min\"]\n",
    "        max_wave_size = surf[\"max\"]\n",
    "\n",
    "        wave_info_dict = {\n",
    "            'spot_id': spot_id,\n",
    "            'timestamp': timestamp,\n",
    "            'min_wave_size': min_wave_size,\n",
    "            'max_wave_size': max_wave_size,\n",
    "            'swell_period': swell_period\n",
    "        }\n",
    "        wave_info.append(wave_info_dict)\n",
    "\n",
    "\n",
    "    wind_response = surf_the_web(id, 'wind')\n",
    "    wind_info = []\n",
    "\n",
    "    for wind in wind_response[\"data\"][\"wind\"]:\n",
    "        spot_id = id\n",
    "        timestamp = unix_time_convert(wind[\"timestamp\"])\n",
    "        speed = wind[\"speed\"]\n",
    "        direction = wind[\"direction\"]\n",
    "        direction_type = wind[\"directionType\"]\n",
    "        wind_info_dict = {\n",
    "            'spot_id': spot_id,\n",
    "            'timestamp': timestamp,\n",
    "            'wind_speed': speed,\n",
    "            'wind_direction': direction,\n",
    "            'wind_type': direction_type\n",
    "        }\n",
    "        wind_info.append(wind_info_dict)\n",
    "\n",
    "    sun_response = surf_the_web(id, 'sunlight')\n",
    "    sun_info = []\n",
    "\n",
    "    for sun in sun_response[\"data\"][\"sunlight\"]:\n",
    "        spot_id = id\n",
    "        timestamp = unix_time_convert(sun[\"dawn\"])\n",
    "        date = timestamp.date()\n",
    "        dawn = unix_time_convert(sun[\"dawn\"])\n",
    "        sunrise = unix_time_convert(sun[\"sunrise\"])\n",
    "        sunset = unix_time_convert(sun[\"sunset\"])\n",
    "        dusk = unix_time_convert(sun[\"dusk\"])\n",
    "        sun_info_dict = {\n",
    "            'spot_id': spot_id,\n",
    "            'date': date,\n",
    "            'dawn': dawn,\n",
    "            'sunrise': sunrise,\n",
    "            'sunset': sunset,\n",
    "            'dusk': dusk\n",
    "        }\n",
    "        sun_info.append(sun_info_dict)\n",
    "    \n",
    "    wave_df = pd.DataFrame(wave_info)\n",
    "    wind_df = pd.DataFrame(wind_info)\n",
    "    sun_df = pd.DataFrame(sun_info)\n",
    "    \n",
    "    result_df = pd.merge(wave_df, wind_df, on=[\"spot_id\", \"timestamp\"], how=\"left\")\n",
    "    result_df['date'] = result_df[\"timestamp\"].dt.date\n",
    "    result_df = pd.merge(result_df, sun_df, on=[\"spot_id\", \"date\"], how=\"left\")\n",
    "    result_df = result_df.drop(columns=[\"date\"])\n",
    "\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# DIST_TRAVEL_LIMIT_HRS = 2\n",
    "TARGET_DATE = get_next_weekend()\n",
    "MIN_WAVE_SIZE = 2\n",
    "MAX_WAVE_SIZE = 3\n",
    "SWELL_PERIOD = 15\n",
    "IDEAL_DURATION = 1.25\n",
    "MAX_DURATION = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Surf Spot Data\n",
    "SURFLINE_URL = (\n",
    "    'https://services.surfline.com/kbyg/mapview'\n",
    "    '?south=48.90805939965008&west=-8.920898437500002&north=52.67638208083924&east=0.7580566406250001&'\n",
    ")\n",
    "\n",
    "response = requests.get(SURFLINE_URL)\n",
    "if response.status_code == 200:\n",
    "    resp_data = response.json()\n",
    "    spots = [\n",
    "        {\n",
    "            \"spot_id\": spot[\"_id\"],\n",
    "            \"spot_name\": spot[\"name\"],\n",
    "            \"sub_region\": spot[\"subregion\"][\"name\"],\n",
    "            \"lat\": spot[\"lat\"],\n",
    "            \"lon\": spot[\"lon\"],\n",
    "        }\n",
    "        for spot in resp_data[\"data\"][\"spots\"]\n",
    "    ]\n",
    "else:\n",
    "    raise RuntimeError(f\"Failed to fetch surf spot data: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "spots_df = pd.DataFrame(spots)\n",
    "\n",
    "# Filter to Relevant Subregions\n",
    "INTEREST_SUBREGIONS = [\n",
    "    'Gower', 'North Cornwall', 'North Devon', 'Severn Estuary',\n",
    "    'South Devon', 'South Cornwall', 'South Pembrokeshire',\n",
    "    'Southern England West', 'Southern England East', 'West Cornwall',\n",
    "]\n",
    "spots_df = spots_df[spots_df[\"sub_region\"].isin(INTEREST_SUBREGIONS)]\n",
    "\n",
    "# Load Pre-calculated Distances\n",
    "distance_data = pd.read_csv(get_distances_path())\n",
    "filtered_spots_df = pd.DataFrame(distance_data)\n",
    "filtered_spots_df['duration_hours'] = round(filtered_spots_df['duration_hours'], 1)\n",
    "\n",
    "filtered_spots_df = filtered_spots_df[filtered_spots_df[\"duration_hours\"] < MAX_DURATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>spot_id</th>\n",
       "      <th>spot_name</th>\n",
       "      <th>sub_region</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>duration_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>584204204e65fad6a77090cf</td>\n",
       "      <td>Newgale</td>\n",
       "      <td>South Pembrokeshire</td>\n",
       "      <td>51.848000</td>\n",
       "      <td>-5.12700</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>69</td>\n",
       "      <td>61415c451b36d771057ffd5f</td>\n",
       "      <td>Freshwater East</td>\n",
       "      <td>South Pembrokeshire</td>\n",
       "      <td>51.646044</td>\n",
       "      <td>-4.86082</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                   spot_id        spot_name           sub_region  \\\n",
       "3    62  584204204e65fad6a77090cf          Newgale  South Pembrokeshire   \n",
       "10   69  61415c451b36d771057ffd5f  Freshwater East  South Pembrokeshire   \n",
       "\n",
       "          lat      lon  duration_hours  \n",
       "3   51.848000 -5.12700             2.9  \n",
       "10  51.646044 -4.86082             2.9  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_spots_df = filtered_spots_df.head(2)\n",
    "filtered_spots_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Surf Data\n",
    "surf_data = pd.DataFrame()\n",
    "for spot_id in filtered_spots_df[\"spot_id\"]:\n",
    "    spot_info = extract(spot_id)\n",
    "    surf_data = pd.concat([surf_data, spot_info], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and Filter by Time Range\n",
    "merged_data = pd.merge(filtered_spots_df, surf_data, on=\"spot_id\", how=\"left\")\n",
    "merged_data[\"timestamp\"] = pd.to_datetime(merged_data[\"timestamp\"])\n",
    "filtered_data = merged_data[\n",
    "    (merged_data[\"timestamp\"] >= merged_data[\"dawn\"])\n",
    "    & (merged_data[\"timestamp\"] <= merged_data[\"dusk\"])\n",
    "    & (merged_data[\"swell_period\"] > 0)\n",
    "    & (merged_data[\"min_wave_size\"] > 0)\n",
    "]\n",
    "\n",
    "# Filter by Target Date\n",
    "date_filtered_data = filtered_data[\n",
    "    filtered_data[\"timestamp\"].dt.strftime(\"%Y-%m-%d\").isin(TARGET_DATE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket Wind Speeds\n",
    "BIN_EDGES = [0, 13, 16, 20, float(\"inf\")]\n",
    "BIN_LABELS = [\"0-12mph\", \"13-15mph\", \"16-20mph\", \"20+mph\"]\n",
    "date_filtered_data[\"wind_speed_bucket\"] = pd.cut(\n",
    "    date_filtered_data[\"wind_speed\"], bins=BIN_EDGES, labels=BIN_LABELS, right=False\n",
    ")\n",
    "\n",
    "# One-Hot Encode Categorical Features\n",
    "COLUMNS_TO_ENCODE = [\"wind_type\", \"wind_speed_bucket\"]\n",
    "encoded_df = pd.get_dummies(date_filtered_data[COLUMNS_TO_ENCODE], prefix=COLUMNS_TO_ENCODE)\n",
    "processed_data = pd.concat(\n",
    "    [date_filtered_data.drop(COLUMNS_TO_ENCODE, axis=1), encoded_df], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "processed_data = normalize_closeness_to_var(processed_data, \"swell_period\", SWELL_PERIOD)\n",
    "processed_data = normalize_closeness_to_var(processed_data, \"min_wave_size\", MIN_WAVE_SIZE)\n",
    "processed_data = normalize_closeness_to_var(processed_data, \"max_wave_size\", MAX_WAVE_SIZE)\n",
    "processed_data = normalize_closeness_to_var(processed_data, \"duration_hours\", IDEAL_DURATION)\n",
    "\n",
    "# Calculate Weighted Scores\n",
    "FEATURE_IMPORTANCE = {\n",
    "    \"wind_type_Cross-shore\": 3,\n",
    "    \"wind_type_Offshore\": 1,\n",
    "    \"wind_type_Onshore\": 8,\n",
    "    \"wind_speed_bucket_0-12mph\": 1,\n",
    "    \"wind_speed_bucket_13-15mph\": 1,\n",
    "    \"wind_speed_bucket_16-20mph\": 6,\n",
    "    \"wind_speed_bucket_20+mph\": 8,\n",
    "    \"normalized_values_swell_period\": 1,\n",
    "    \"normalized_closeness_min_wave_size\": 1,\n",
    "    \"normalized_closeness_max_wave_size\": 1,\n",
    "    \"normalized_values_duration_hours\": 3,\n",
    "}\n",
    "\n",
    "valid_columns = [col for col in FEATURE_IMPORTANCE if col in processed_data]\n",
    "processed_data[\"weighted_sum\"] = sum(\n",
    "    (6 - FEATURE_IMPORTANCE[col]) * processed_data[col] for col in valid_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `processed_data` is your DataFrame\n",
    "# Convert `timestamp` column to datetime if not already done\n",
    "processed_data['timestamp'] = pd.to_datetime(processed_data['timestamp'])\n",
    "\n",
    "# Extract the date part\n",
    "processed_data['date'] = processed_data['timestamp'].dt.date\n",
    "\n",
    "# Rank the rows based on `weighted_sum` within each date partition\n",
    "processed_data['rank'] = processed_data.groupby('date')['weighted_sum'].rank(ascending=False, method='dense')\n",
    "\n",
    "# Filter the top 3 for each date\n",
    "top_3 = processed_data[processed_data['rank'] == 1]\n",
    "\n",
    "# Sort the final output by date and rank\n",
    "top_3 = top_3.sort_values(by=['date', 'rank']).reset_index(drop=True)\n",
    "\n",
    "if \"wind_type_Offshore\" not in top_3.columns:\n",
    "    top_3['wind_type_Offshore'] = False\n",
    "if \"wind_type_Onshore\" not in top_3.columns:\n",
    "    top_3['wind_type_Onshore'] = False\n",
    "if \"wind_type_Cross-shore\" not in top_3.columns:\n",
    "    top_3['wind_type_Cross-shore'] = False\n",
    "\n",
    "final_columns = [\n",
    "    'spot_name', \n",
    "    'sub_region', \n",
    "    'timestamp', \n",
    "    'duration_hours', \n",
    "    'min_wave_size', \n",
    "    'max_wave_size', \n",
    "    'swell_period', \n",
    "    'wind_speed', \n",
    "    'dawn', \n",
    "    'sunrise', \n",
    "    'sunset', \n",
    "    'dusk', \n",
    "    'wind_type_Cross-shore', \n",
    "    'wind_type_Offshore', \n",
    "    'wind_type_Onshore', \n",
    "    'rank', \n",
    "    'weighted_sum'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spot_name</th>\n",
       "      <th>sub_region</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration_hours</th>\n",
       "      <th>min_wave_size</th>\n",
       "      <th>max_wave_size</th>\n",
       "      <th>swell_period</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>dawn</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>dusk</th>\n",
       "      <th>wind_type_Cross-shore</th>\n",
       "      <th>wind_type_Offshore</th>\n",
       "      <th>wind_type_Onshore</th>\n",
       "      <th>rank</th>\n",
       "      <th>weighted_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [spot_name, sub_region, timestamp, duration_hours, min_wave_size, max_wave_size, swell_period, wind_speed, dawn, sunrise, sunset, dusk, wind_type_Cross-shore, wind_type_Offshore, wind_type_Onshore, rank, weighted_sum]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(top_3[final_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
